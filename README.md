This repo contains code to evaluate explainability algorithms in terms of their explanation quality. A suite of multifaceted metrics are implemented to objectively compare explainers based on correctness, consistency, as well as the confidence of the generated explanations. These metrics are computationally inexpensive, do not require model-retraining and can be used across different data modalities. 

Currently, common explainers such as Grad-CAM, SmoothGrad, LIME and Integrated Gradients are considered, and they are applied on images. 


