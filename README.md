#This repo contains code to evaluate explainability algorithms in terms of their explanation quality. A suite of multifaceted metrics are implemented to objectively compare explainers based on correctness, consistency, as well as the confidence of the generated explanations.
These metrics are computationally inexpensive, do not require model-retraining
and can be used across different data modalities. We evaluate them on common
explainers such as Grad-CAM, SmoothGrad, LIME and Integrated Gradients. Our
experiments show that the proposed metrics reflect qualitative observations reported in earlier works.
